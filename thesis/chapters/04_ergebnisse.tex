% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Ergebnisse}\label{chapter:ergebnisse}
Im Folgenden wird die \Cpp\hyp Implementierung experimentell evaluiert.
Die zwei zentralen Kenngrößen des Algorithmus sind die Laufzeit und die Schnittkosten der ausgegebenen Partitionierung.
Dabei werden die Schnittkosten, mit denen verglichen, die durch die Heuristiken METIS~\cite{KK98} und KaHIP~\cite{SS13} erreicht werden.
Da der Algorithmus dieser Arbeit ausschließlich auf Bäumen arbeitet, wird zunächst das Verhalten dieser Kenngrößen in Abhängigkeit der Eingabeparameter auf Bäumen untersucht.
Anschließend werden die Schnittkosten auf generellen Graphen untersucht.
Dazu wird zu einem Graph ein entsprechender Baum generiert und der Algorithmus wird auf den Baum angewandt.
Danach wird die Partitionierung des Baums in eine Partitionierung des Graphen umgewandelt.

\section{Bäume}
Es wurden vier verschiedene Heuristiken verwendet, um zufällige Bäume zu generieren.
Die erste Heuristik wird im Weiteren als Random Attachment bezeichnet. 
Ein Baum mit $n$ Knoten wird generiert, indem mit einem Knoten gestartet wird und iterativ Blätter an zufällige Knoten des Baums angehängt werden, bis die gewünschte Knotenanzahl $n$ erreicht ist.
Eine weitere Heuristik, die eine abgewandelte Version des Random Attachments ist, wird als Preferential Attachment bezeichnet.
Dabei wird eine neues Blatt nicht zufällig mit einer uniformen Verteilung an einen Knoten des Baums angehängt, sondern die Wahrscheinlichkeit ist proportional zum Grad des Knotens.
Bei den beiden oben genannten Heuristiken kann zusätzlich der Maximalgrad für die Knoten des Baums festgelegt werden.
Die dritte Heuristik sind sogenannte Fat Trees.
Für diese Heuristik wird wiederum mit einem Knoten in Level $0$ gestartet.
Für das Level $\ell \geq 1$ des Baums wird aus einer gegebenen Menge zufällig eine Zahl $d$ ausgewählt.
Dann werden an alle Knoten des Levels $\ell - 1$ genau $d$ Kinder angehängt.
Dies wird wiederholt, bis der Baum die gewünschte Anzahl an Knoten hat. 
Dementsprechend kann es sein, dass das letzte Level nicht vollständig mit Knoten gefüllt ist.
Fat Trees sind eine Verallgemeinerung von fast vollständigen balancierten $d$\hyp ären Bäumen.
Wir erhalten einen fast vollständigen balancierten $d$\hyp ären Baum, indem wir die Menge der möglichen Kinderanzahlen des Fat Trees auf $\{d\}$ setzen.
Für alle Heuristiken werden die Kantengewichte der Bäume mit einer uniformen Zufallsverteilung aus dem Bereich $[1, 100]$ gewählt.

\subsection{Laufzeit}\label{sec:exprun}
Um die Laufzeit des Algorithmus zu analysieren, wurde wiederholt ein Parameter gewählt, dessen Auswirkung auf die Laufzeit untersucht werden soll.
Die anderen Parameter wurden festgesetzt und bleiben konstant.
Dann wurde der gewählte Parameter schrittweise verändert.
Um Schwankungen auszugleichen, wurden für jede Kombination der Parameter 20 verschiedene Bäume mit den oben genannten Heuristiken generiert und die Laufzeit für jeden Baum gemessen.
Dabei wurde die Anzahl der Kinder des Fat Trees aus der Menge $\{2, \ldots, 10\}$ gewählt und als $d$\hyp ärer Baum wurde ein Binärbaum gewählt.
Des Weiteren wurden für die übrigen Parameter jeweils drei verschieden Konfigurationen gewählt.
Alle Zeitmessungen wurden auf einem System mit $8$ GB Arbeitsspeicher und einem Intel i7-4790k Prozessor mit einer Taktrate von $4.0$ GHz durchgeführt.
Das Program wurde mit Clang der Version \texttt{3.8.1} unter der Verwendung von Optimierungsstufe O3 kompiliert.

In den Abbildungen~\ref{fig:runnodes},~\ref{fig:runimb},~\ref{fig:runkparts} und~\ref{fig:rundeg} werden die gemessenen Zeiten mit Boxplots dargestellt.
Ein Boxplot besteht aus einer oberen Antenne, einer unteren Antenne, dem oberen Quartil, dem unteren Quartil und dem Median.
Die obere Antenne und die untere Antenne stellen jeweils das Maximum beziehungsweise das Minimum der gemessenen Werte dar, falls es keine Ausreißer gibt, die weit vom Rest der Werte entfernt sind.
In den Messergebnissen kamen in fast allen Fällen pro 20 Durchläufen höchstens drei Ausreißer nach oben vor.
Nur für kleines $\eps$ kamen bis zu fünf Ausreißer vor.
Weiterhin liegen $75\%$ der gemessen Werte unterhalb des oberen Quartils, während $25\%$ unterhalb des unteren Quartils liegen.
Das obere und untere Quartil werden zu einer Box zusammengefasst.
Zuletzt sind $50\%$ der Werte kleiner als der Median, welcher durch einen Querstrich dargestellt wird.

Abbildung~\ref{fig:runnodes} zeigt die Laufzeit im Millisekunden in Abhängigkeit der Knotenanzahl $n$ des Baums.
Für jede Heuristik wurde eine Messreihe mit verschiedenen Konfigurationen der übrigen Parametern angelegt.
Dabei wird die jeweilige Heuristik in der Graphüberschrift genannt und den verschiedenen Parameterkonfigurationen sind unterschiedliche Farben zugewiesen. 
Des Weiteren wurde eine Messreihe erstellt, welche die Abhängigkeit der Laufzeit von der Knotenanzahl für höhere Knotenanzahlen zeigt.
Dabei wurde $k=2$ und $\eps=1/2$ gesetzt und für jede Knotenanzahl ein Baum jeder Heuristik generiert und die Laufzeit gemessen.
Die Ergebnisse dieser Messreihe sind in Tabelle~\ref{tab:highnodecnt} zu sehen.

\begin{figure}[t]
    \centering
    \includestandalone{figures/trees/runtime/node_count}
    \caption{Laufzeit in Abhängigkeit der Knotenanzahl\label{fig:runnodes}}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{l*{4}{c}}
        \toprule
        & 100 & 200 & 400 & 800 \\
        \midrule
        Random Attachment & 82 & 1249 & 26505 & 451628 \\ 
        Preferential Attachment & 49 & 452 & 9741 & 160347 \\
        Fat Tree & 23 & 496 & 10941 & 139296 \\ 
        Binärbaum & 132 & 2228 & 37758 & 644216 \\ 
        \bottomrule
    \end{tabular}
    \caption{Die Laufzeit in Millisekunden in Abhängigkeit der Knotenanzahl und Baumheuristik mit $k=2$ und $\eps=1/2$\label{tab:highnodecnt}}
\end{table}

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/runtime/imbalance}
    \caption{Laufzeit in Abhängigkeit des Ungleichgewichts\label{fig:runimb}}
\end{figure}

Die Abbildung~\ref{fig:runimb} ist aufgebaut wie die vorherige Abbildung, zeigt jedoch die Laufzeit in Abhängigkeit des Ungleichgewichts $\eps$.
Ein Ungleichgewicht von $\eps$ bedeutet, dass jede Partition der ermittelten Partitionierung höchstens eine Größe von $(1 + \eps) \ceil{n/k}$ hat.

In Abbildung~\ref{fig:runkparts} ist die Laufzeit in Abhängigkeit der Anzahl an Partitionen $k$ zu sehen.
Weiterhin gilt zu bemerken, dass die Laufzeit für steigendes $k$ zunächst zunimmt und dann wieder abnimmt.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/runtime/kparts}
    \caption{Laufzeit in Abhängigkeit der Teilanzahl\label{fig:runkparts}}
\end{figure}

Die letzte Abbildung~\ref{fig:rundeg} visualisiert die Laufzeit in Abhängigkeit des Maximalgrads $\Delta$.
Hierbei wurde die Heuristik Random Attachment weggelassen, da es unwahrscheinlich ist, dass der Maximalgrad bei größeren Werten erreicht wird.
Beim Fat Tree wurde weiterhin zwei für die Mindestanzahl an Kindern gewählt, während die Maximalanzahl $\Delta - 1$ ist.
Anstatt eines Binärbaums wurde ein $d$\hyp ärer Baum betrachtet und die Entwicklung der Laufzeit mit wachsendem $d$ untersucht.
Wie zu sehen ist nimmt die Laufzeit mit wachsendem Maximalgrad ab.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/runtime/max_degree}
    \caption{Laufzeit in Abhängigkeit des Maximalgrads\label{fig:rundeg}}
\end{figure}

Insgesamt ist die geringe Streuung der Werte beim Binärbaum bemerkenswert.
Des Weiteren zeichnet sich der Binärbaum durch eine höhere Laufzeit und der Fat Tree durch eine geringere Laufzeit aus.

\subsection{Lösungsqualitat}
In dieser Sektion wird die Lösungsqualität des Algorithmus auf Bäumen evaluiert.
Nach bestem Wissen des Autors gibt es keine Implementierung eines vergleichbaren Approximationsalgorithmus und deshalb wird die Lösungsqualität durch einen Vergleich mit Heuristiken beurteilt.
Da es sich bei dem $(k,1+\eps)$\hyp Partitionierungsproblem um ein Problem handelt, dass viele Praxisanwendungen hat, wurden bereits einige heuristische Ansätze entwickelt. 
Das Survey~\cite{BMS+16} gibt einen Überblick über die verschiedenen Ansätze.

In dieser Arbeit wird die Lösungsqualität mit den Heuristiken METIS~\cite{KK98} und KaHIP~\cite{SS13} verglichen.
Beide Heuristiken verwenden eine Multilevel-Schema.
Dabei wird der Graph zuerst in mehreren Schritten verkleinert, indem Kanten kontrahiert werden.
Danach wird im verkleinerten Graph eine Partitionierung mit hoher Qualität berechnet.
Zuletzt werden die kontrahierten Kanten wieder expandiert, wobei in jedem Schritt lokale Verbesserungen der Partitionierung durchgeführt werden.
Um die Kanten zu kontrahieren, werden Matchings verwendet.
METIS und KaHIP behaupten, Partitionierungen mit hoher Qualität im Vergleich zu anderen viel verwendeten Heuristiken zu finden.
KaHIP gelang es, bei der zehnten DIMACS Implementation Challenge~\cite{BMS+13} die beste Lösungsqualität im Vergleich zu anderen Heuristiken zu erreichen.

Für die folgenden Versuche wurden von METIS die Graphpartitionierungsmethoden METIS recursive und METIS k-way verwendet.
Alle zusätzlichen Konfigurationsoptionen, die METIS bereitstellt, wurden auf den Standartwerten belassen.
Von KaHIP wird der Karlsruhe Fast Flow Partitioner (KaFFPa) verwendet.
KaFFPa stellt verschieden Modi bereit, die die Laufzeit und die Lösungsqualität beeinflussen.
Hier wurde der Modus STRONG gewählt, der zu einer höheren Laufzeit führt, aber die beste Lösungsqualität bietet.
In den Experimenten werden kleine Graphen verwendet, wodurch die erhöhte Laufzeit nicht ins Gewicht fällt.
Alle anderen Optionen wurden nicht verändert.
Bei der Berechnung der Partitionierung erhalten der Algorithmus dieser Arbeit sowie die Heuristiken METIS und KaHIP dieselben Parameter $k$ und $\eps$.
Um die Eingabebäume zu generieren, werden die gleichen Methoden wie in der vorherigen Sektion~\ref{sec:exprun} verwendet.
Hierbei wurden jeweils 20 unterschiedliche Bäume für jede Baumheuristik generiert.

Die Abbildungen~\ref{fig:mrectreesnodes},~\ref{fig:mkwaytreesnodes} und~\ref{fig:kaffpatreesnodes} zeigen die relative Lösungsqualität der jeweiligen Graphpartitionierungsheuristik in Abhängigkeit der Knotenanzahl $n$.
Wenn der Algorithmus dieser Arbeit auf einem Graphen eine Partitionierung mit Kosten $c_A$ berechnet und die Heuristik eine Partitionierung mit Kosten $c_H$, dann berechnet sich die relative Lösungsqualität durch 
\begin{equation*}
    \frac{c_A}{c_H}. 
\end{equation*}

Das bedeutet, dass der Algorithmus dieser Arbeit eine günstigere Partitionierung als eine Graphpartitionierungsheuristik gefunden hat, wenn die relative Lösungsqualität kleiner als $1$ ist.
Andernfalls liefert die Heuristik ein besseres Ergebnis.
Für alle Experimente wurde $\eps=1/3$ gewählt.
Außerdem wurden für jeden Baum Durchläufe mit $k \in \{2, 4, 6\}$ durchgeführt, welche unterschiedlich eingefärbt sind.

Für METIS recursive in Abbildung~\ref{fig:mrectreesnodes} fällt auf, dass die relative Lösungsqualität mit wachsendem $k$ steigt.
Relativ zu METIS recursive ist die Performanz des Algorithmus dieser Arbeit damit für höheres $k$ schlechter.
Außerdem treten Ausreißer nach unten hautpsächlich für $k=2$ auf.
Für $k=6$ kommen auch Ausreißer vor, deren Wert über $1$ liegt, das heißt, in diesem Fall hat METIS recursive eine bessere Partitionierung gefunden als der Algorithmus dieser Arbeit.
Dazu muss jedoch erwähnt werden, dass einige dieser Partitionierungen das gegebene Ungleichgewicht $\eps=1/3$ verletzen, da diese Partitionierungen Partitionen enthalten, die größer als $(1+\eps) \ceil{n/k}$ sind.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/node_count/metis_recursive}
    \caption{Relative Lösungsqualität von METIS recursive in Abhängigkeit der Knotenanzahl $n$\label{fig:mrectreesnodes}}
\end{figure}

Wie vorher ist bei METIS k-way die relative Lösungsqualität geringer für $k=2$, wie in Abbildung~\ref{fig:mkwaytreesnodes} zu sehen ist.
Zwischen $k=4$ und $k=6$ ist jedoch kein klarer Unterschied zu sehen.
Außerdem weist METIS k-way für $k=2$ einige Ausreißer mit sehr niedrigen relativen Lösungsqualität auf, während hingegen nur ein Ausreißer mit einem Wert von mehr als $1$ auftritt.
Damit liefert der Algorithmus dieser Arbeit im Vergleich zu METIS k-way eine gute Lösungsqualität.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/node_count/metis_kway}
    \caption{Relative Lösungsqualität von METIS k-way in Abhängigkeit der Knotenanzahl $n$\label{fig:mkwaytreesnodes}}
\end{figure}

Die Heuristik KaFFPa erreicht im Vergleich zu METIS recursive und METIS k-way eine bessere relative Lösungsqualität.
Dabei treten auch vergleichsweise wenig Ausreißer mit eine Wert von unter $0.2$ auf.
Die relative Lösungsqualität bei KaFFPa ändert sich nicht merklich mit wachsendem $k$.
Insgesamt wird keine Abhängigkeit der relativen Lösungsqualität von der Knotenanzahl für die gewählten Parameter sichtbar.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/node_count/kaffpa}
    \caption{Relative Lösungsqualität von KaFFPa in Abhängigkeit der Knotenanzahl $n$\label{fig:kaffpatreesnodes}}
\end{figure}

Die folgenden Abbildungen~\ref{fig:mrectreesimb},~\ref{fig:mkwaytreesimb} und~\ref{fig:kaffpatreesimb} zeigen die relative Lösungsqualität in Abhängigkeit von $\eps$ für $n=80$.
Die verschiedenen Werte für $k \in \{2,4,6\}$ sind weiterhin entsprechend eingefärbt.
Wiederum liefern METIS recursive und METIS k-way für $k=2$ meist eine geringe relative Lösungsqualität.
Wie vorher liefert KaFFPa die besten Ergebnisse.
Alles in Allem ist keine klare Abhängigkeit der relativen Lösungsqualität von $\eps$ für die gegebenen Parameter zu sehen.

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/imbalance/metis_recursive}
    \caption{Relative Lösungsqualität von METIS recursive in Abhängigkeit des Ungleichgewichts $\eps$\label{fig:mrectreesimb}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/imbalance/metis_kway}
    \caption{Relative Lösungsqualität von METIS k-way in Abhängigkeit des Ungleichgewichts $\eps$\label{fig:mkwaytreesimb}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/trees/quality/imbalance/kaffpa}
    \caption{Relative Lösungsqualität von KaFFPa in Abhängigkeit des Ungleichgewichts $\eps$\label{fig:kaffpatreesimb}}
\end{figure}

\section{Lösungsqualität auf Graphen}
Nachdem in der vorherigen Sektion die relative Lösungsqualität der Heuristiken auf Bäumen behandelt wurde, werden nun Graphen untersucht.
Da der Algorithmus dieser Arbeit jedoch nur auf Bäume angewandt werden kann, muss ein Eingabegraph vorher in einen Baum umgewandelt werden.
Die Partitionierung der Knoten, die der Algorithmus dieser Arbeit auf dem Baum findet, wird dann auf eine des Graphen übertragen.
Dafür kann eine hierarchische Dekomposition verwendet werden, wie sie in Sektion~\ref{sec:decomptrees} vorgestellt wurde.
Der genannte Algorithmus kann jedoch nicht verwendet werden, da es keine Implementierung gibt.
Anstattdessen wird ein ähnlicher Algorithmus benutzt, der von Räcke, Shah und Täubig~\cite{RST14} entwickelt wurde.
Im Gegensatz zum Algorithmus aus Sektion~\ref{sec:decomptrees} gibt dieser Algorithmus nur einen einzigen Baum aus.
Allerdings ist der Approximationsfaktor mit $\bigO(\log^4 n)$ schlechter.
Der Algorithmus wurde von Moritz Fuchs implementiert und ist auf Github verfügbar.\footnote{Repositorium auf Github: \url{https://github.com/moritzFuchs/hierarchical-decomposition}}
Da für diesen Algorithmus nur die Blätter des Baums mit den Knoten des Graphen korrespondieren, wird die Partitionierung der Blätter als die Partitionierung des Graphen verwendet.
Des Weiteren wurden Experimente mit zufälligen Spannbäumen (RST) und minimalen Spannbäumen (MST) durchgeführt.
Für diese Methoden kann eine Partitionierung des Baums direkt in eine Partitionierung des Graphen umgewandelt werden, da beide dieselbe Knotenmenge besitzen.
Als Eingabegraphen werden sowohl Zufallsgraphen als auch reale Daten verwendet.

\subsection{Zufallsgraphen}
Zufällige Eingabegraphen werden nach zwei verschiedenen Modellen generiert.
Das erste Modell wird Erdős-Rényi-Modell und das zweite Barabási-Albert-Modell genannt.
Diese Modelle wurden unter anderem von Barabási und Albert~\cite{AB02} analysiert.
Das Erdős-Rényi-Modell generiert einen Graphen $G=(V,E)$ mit $n$ Knoten für eine Wahrscheinlichkeit $p$, indem für jede mögliche Kante $\{u, v\} \in E$ mit einer Bernoulliverteilung mit Parameter $p$ entschieden wird, ob die Kante existiert.
Das Barabási-Albert-Modell erzeugt einen Graphen $G=(V,E)$ mit $n$ Knoten für ein Kantenanzahl $m$ aus einem Graphen $H$ mit $m_0$ Knoten, wobei $m \leq m_0 \leq n$ gilt.
Um $G$ zu erhalten, werden nacheinander $n - m_0$ Knoten zu $H$ hinzugefügt.
Jeder dieser Knoten wird mit $m$ Knoten in $H$ verbunden, welche zufällig mit einer Wahrscheinlichkeit proportional zu ihrem Grad gewählt werden.

Die Kantengewichte für beide Modelle werden uniform aus dem Bereich $[1, 100]$ gewählt.
Falls ein Knoten im Barabási-Albert-Modell zweimal in einem Schritt gewählt wird, dann werden die Kantengewichte addiert.
Der Grad erhöht sich dadurch nicht.
Im Falle des Barabási-Albert-Modells ist der initiale Graph $H$ für den Parameter $m$ ein Kreis mit $m$ Knoten.
Für jeden Kombination aus Knotenanzahl und Parameter des jeweiligen Modells wurden zehn Graphen generiert.

Für die folgenden Experimente wurde $\eps=1/3$ gewählt und $k \in \{2, 4, 6\}$, wobei die Ergebnisse für die verschiedenen Werte von $k$ farblich voneinander abgesetzt sind.
Die Abbildungen~\ref{fig:edgeprobrstnode},~\ref{fig:edgeprobmstnode} und~\ref{fig:edgeprobhdecompnode} zeigen die relativen Schnittkosten der Heuristiken METIS recursive, METIS k-way und KaFFPa in Abhängigkeit der Knotenanzahl für das Erdős-Rényi-Modell mit $p=0.1$ beziehungsweise $p=0.3$.
Die Ergebnisse bei der Verwendung von RST und MST sind ähnlich, wobei die Performanz des MST insgesamt etwas schlechter ist.
In beiden Fällen sinken die relativen Schnittkosten für wachsendes $k$, was im Gegensatz zu den Resultaten auf Bäumen steht.
Wenn hierarchische Dekomposition verwendet wird, dann ist die relative Lösungsqualität für deutlich $k=2$ geringer, während für $k=4$ und $k=6$ die Qualität gleich ist.
Insgesamt ist die Qualität für $p=0.3$ in allen Fällen besser als für $p=0.1$.
Zwischen den verschiedenen Graphpartitionierungsheuristiken besteht kein wesentlicher Unterschied in der relativen Lösungsqualität.

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/edge_prob_rst}
    \caption{Relative Lösungsqualität für das Erdős-Rényi-Modell und RST in Abhängigkeit der Knotenanzahl $n$\label{fig:edgeprobrstnode}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/edge_prob_mst}
    \caption{Relative Lösungsqualität für das Erdős-Rényi-Modell und MST in Abhängigkeit der Knotenanzahl $n$\label{fig:edgeprobmstnode}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/edge_prob_decomp}
    \caption{Relative Lösungsqualität für das Erdős-Rényi-Modell und Hierarchical Decomposition in Abhängigkeit der Knotenanzahl $n$\label{fig:edgeprobhdecompnode}}
\end{figure}


In den Abbildungen~\ref{fig:prefattachrstnode},~\ref{fig:prefattachmstnode} und~\ref{fig:prefattachhdecompnode} ist die relative Lösungsqualität der Graphpartitionierungsheuristiken in Abhängigkeit für das Barabási-Albert-Modell mit den Parameter $m=5$ und $m=10$ zu sehen.
Wie vorher ist die relative Lösungsqualität für RST und MST im Fall $k=2$ höchsten, während sie hingegen für hierarchische Dekomposition am niedgrigsten ist.
Für $k=2$ und $k=4$ ist der Unterschied gering.
Weiterhin weist die relative Lösungsqualitat der Graphpartitionierungsheuristiken insgesamt nur geringe Unterschiede auf.
Außerdem ist hierarchische Dekomposition auf Eingabegraphen des Barabási-Albert-Modells merkbar besser als MST und RST.
Ferner gibt es Ausreißer mit einem Wert kleiner als $1$.
Analog zum Erdős-Rényi-Modell ist die relative Lösungsqualität für eine höhere Anzahl von Kanten geringer, das hießt der Algorithmus dieser Arbeit liefert relativ gesehen bessere Ergebnisse.

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/pref_attach_rst}
    \caption{Relative Lösungsqualität für das Barabási-Albert-Modell und RST in Abhängigkeit der Knotenanzahl $n$\label{fig:prefattachrstnode}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/pref_attach_mst}
    \caption{Relative Lösungsqualität für das Barabási-Albert-Modell und MST in Abhängigkeit der Knotenanzahl $n$\label{fig:prefattachmstnode}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/node_count/pref_attach_decomp}
    \caption{Relative Lösungsqualität für das Barabási-Albert-Modell und Hierarchical Decomposition in Abhängigkeit der Knotenanzahl $n$\label{fig:prefattachhdecompnode}}
\end{figure}


Zuletzt wird die relative Lösungsqualität in Abhängigkeit des Ungleichgewichts $\eps$ untersucht.
Dafür wird $n=80$ gewählt und $k \in \{2, 4, 6\}$, wobei die Einfärbung der Ergebnisse den unterschiedlichen Werten von $k$ entspricht.
Dabei wurden RST und MST weggelassen, da zwischen MST, RST und hierarchischer Dekomposition beim Erdős-Rényi-Modell keine wesentlichen Unterschiede in der relativen Lösungsqualität bestanden und hierarchische Dekomposition für das Barabási-Albert-Modell bessere Ergbnisse lieferte.
Die ausgelassenen Resultate sind in Anhang~\ref{chapter:rapp} zu finden.
Die übrigen Ergebnisse sind in Abbildung~\ref{fig:edgeprobhdecompimb} und~\ref{fig:prefattachhdecompimb} zu sehen.
Das Verhalten für $k=2$ ist weitgehend wie oben, wobei zusätzlich auffällt, dass die relative Lösungsqualität mit fallendem $\eps$ abnimmt.
Den Experimenten nach scheinen für $k=4$ und $k=6$ verschiedene Werte von $\eps$ keinen Einfluss auf die relative Lösungsqualität zu haben.

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/imbalance/edge_prob_decomp}
    \caption{Relative Lösungsqualität für das Erdős-Rényi-Modell und Hierarchical Decomposition in Abhängikeit von $\eps$\label{fig:edgeprobhdecompimb}}
\end{figure}

\begin{figure}[H]
    \centering
    \includestandalone{figures/graphs/imbalance/pref_attach_decomp}
    \caption{Relative Lösungsqualität für das Barabási-Albert-Modell und Hierarchical Decomposition in Abhängikeit von $\eps$\label{fig:prefattachhdecompimb}}
\end{figure}

\subsection{Graphen aus realen Daten}
Zum Schluss wird die relative Lösungsqualität des Algorithmus dieser Arbeit anhand von realen Datensätzen durch einen Vergleich mit den Heuristiken METIS recursive, METIS k-way und KaFFPa ermittelt.
Alle verwendeten Datensätze sind in der Stanford Large Network Dataset Collection enthalten.~\cite{LK14}
Die folgende Tabelle gibt einen Überblick über diese Datensätze.
Dabei ist ein Dreieck eine Menge von drei Knoten, die alle untereinander verbunden sind.

\begin{table}[H]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        Datensatz & Knoten & Kanten & Anzahl der Dreiecke & Referenz \\
        \midrule
        as19990829 & 103 & 248 & 228 & \cite{LKF05} \\
        email-Eu-core & 1005 & 25571 & 105461 & \cite{LKF07} \\
        ca-GrQc & 5242 & 14496 & 48260 & \cite{LKF07} \\
        ego-Facebook & 4039 & 88234 & 1612010 & \cite{ML14} \\
        \bottomrule
    \end{tabular}
    \caption{Überblick über die Datensätze}
\end{table}

Wie in der Tabelle zu sehen ist, haben die Graphen in drei von vier Fällen über $1000$ Knoten.
Außerdem erhöht die Umwandlung des Graphen in einen Baum mit hierarchischer Dekomposition die Anzahl der Knoten. 
Damit liegen diese Graphen außerhalb der Möglichkeiten des Algorithmus dieser Arbeit, da die Laufzeit zu hoch ist.
Deshalb muss der Graph zuerst verkleinert werden, bevor er in einen Baum umgewandelt wird.

Dafür wurde ein Verfahren verwendet, welches Heavy Edge Matching genannt wird und bereits von Karypis und Kumar~\cite{KK98} für die Verkleinerung von Graphen für die Heuristik METIS vorgeschlagen und experimentell evaluiert wurde.
Das Verfahren verkleinert den Graph iterativ, indem in jedem Schritt ein Matching ermittelt wird und alle Kanten des Matchings kontrahiert werden.
Das Matching wird folgendermaßen berechnet:
Die Knoten werden anhand einer zufälligen Reihenfolge besucht und es wird der Knoten $v$ mit dem adjazenten Knoten $u$ gematcht, falls die Kante $\{v, u\}$ die Kante mit maximalen Gewicht ist, sodass weder $v$ noch $u$ bereits gematcht sind.
Wenn es keine solche Kante gibt, dann wird mit dem nächsten Knoten fortgefahren.
Es gilt zu bemerken, dass mit diesem Verfahren in der Regel nicht das größtmögliche Matching gefunden wird.
Falls durch die Kontraktion parallele Kanten entstehen würden, dann werden die Kantengewichte addiert.
Außerdem werden die Knotengewichte der kontrahierten Knoten addiert, wobei die Knoten zu Anfang uniform gewichtet sind.
Hier kommt die Erweiterung des Algorithmus auf Bäume mit Knotengewichten aus Sektion~\ref{sec:nodeweights} zum tragen.
Die obigen Schritte werden so lange wiederholt bis der Graph auf die gewünschte Knotenanzahl verkleinert wurde.
Wichtig ist, dass das beschrieben Verfahren die Schnittkosten der Partitionierung im Graphen nicht verändert, sondern nur Partitionierungen unmöglich macht.

In unserem Fall werden die Graphen aus den drei größeren Datensätzen auf $100$ Knoten kontrahiert.
Anschließend wird die hierarchische Dekomposition auf den Graphen angewendet.
Dann wird der Baum partitioniert und die Partitionierung der Blätter des Baums wird auf den Graph angewandt.
Für jeden Datensatz wurde die relative Lösungsqualität für alle Kombinationen aus Partitionsanzahl $k \in \{2,3,4,6\}$ und Ungleichgewicht $\eps \in \{8/20, 7/20, 6/20, 5/20\}$ ermittelt, falls die Laufzeit und der Speicherbedarf des Algorithmus dies zuließ.
Die Ergebnisse für verschieden $k$ sind unterschiedlich eingefärbt.

Der erste Datensatz trägt den Namen as19990829 und ist ein Graph mit $103$ Knoten und $248$ Kanten.
Dieser Datensatz ist das Kommunikationsnetzwerk eines autonomen Systems, wobei ein autonomes System ein Subnetzwerk von Routern im Internet ist.
Die Abbildung~\ref{fig:as} zeigt die Resultate.
Wie bei den Zufallsgraphen ist die relative Lösungsqualität für $k=2$ am kleinsten.
Des Weiteren steigt die relative Lösungsqualität von KaFFPa mit steigendem $k$.
Bemerkenswert ist die geringe relative Lösungsqualität von METIS recursive.
Auf der anderen Seite ist der Algorithmus für keine Parameterkombination besser als KaFFPa, wobei es interessant ist, dass der Algorithmus und KaFFPa in drei Fällen Partitionierungen mit identischen Kosten finden.
Das Ungleichgewicht $\eps$ scheint nur bei METIS für $k=2$ einen Einfluss auf die relative Lösungsqualität zu haben.


Der zweite Datensatz heißt email-Eu-core und ist ein gerichteter Graph mit $1005$ Knoten und $25571$ Kanten.
Dabei handelt es sich um ein eMail\hyp Kommunikationsnetzwerk einer europäischen Forschungseinrichtung.
Das Netzwerk umfasst nur die Kommunikation von Mitgliedern der Institution und enthält eine Kante $(u, v)$, falls Person $u$ mindestens eine eMail an Person $v$ geschickt hat.
Da der Algorithmus dieser Arbeit nur ungerichtete Bäume partitioniert, wurden die gerichteten Kanten in ungerichtete umgewandelt.
Wie in Abbildung~\ref{fig:email} zu sehen ist, ist die relative Lösungsqualität von METIS recursive und METIS k-way wiederum für $k=2$ minimal.
Bei KaFFPa zeigen sich keine Unterschiede für verschieden Werte von $k$.
Interessanterweise verschlechtert sich die Lösungsqualität im Vergleich zum Datensatz as19990829 nur leicht, obwohl der Graph zunächst kontrahiert wird.
Weiterhin steigt die relative Lösungsqualität von METIS recursive und METIS k-way für fallendes $\eps$.

Der dritte Datensatz ca-GrQc ist ein Graph mit $5242$ Kanten und $25571$ Kanten.
Dieser stellt ein Kollaborationsnetzwerk von Wissenschaftlern innerhalb des Felds der Relativitätstheorie dar.
Für diesen Graph konnten die Experimente für $k=6$ nicht durchgeführt werden, da die Laufzeit und der Speicherbedarf zu hoch sind. 
Der Grund hierfür ist, dass dieselbe Signatur für verschiedene Gewichtssummen mehrmals vorkommen kann. 
Wenn die mögliche Gesamtsumme an Knotengewichten höher ist, dann steigt die Anzahl an Signaturen und damit die Laufzeit sowie der Speicherbedarf.
Die Abbildung~\ref{fig:cagrqc} zeigt die Ergebnisse der Experimente.
Obwohl dieser Graph deutlich größer ist als die vorherigen, ist die Lösungsqualität des Algorithmus dieser Arbeit im Vergleich zu den Heuristiken hoch.
Des Weiteren ist KaFFPa für diesen Graph merkbar besser als beide Methoden von METIS.
In diesem Graph verändert sich die relative Lösungsqualität nicht in Abhängigkeit von $\eps$.

Der letzte Datensatz heißt ego-Facebook und ist ein Graph mit $4039$ Knoten und $88234$ Kanten.
Dieser Graph bildet Freundeslisten im sozialen Netzwerk facebook\footnote{\url{https://facebook.com}} ab.
Auch für diesen Graph war es nicht möglich, die Schnittkosten für $k=6$ zu berechnen.
Wie die Abbildung~\ref{fig:facebook} zeigt, ist die relativen Lösungsqualität in diesem Graph deutlich höher als in den vorherigeren Graphen, besonders für $k=3$ und $k=4$.
Während die relative Lösungsqualität für $k=2$ mit fallendem $\eps$ steigt, sinkt sie für $k=4$ auf der anderen Seite tendenziell.

\begin{figure}[t]
    \centering
    \includestandalone{figures/graphs/data_sets/as}
    \caption{Relative Lösungsqualität für den Datensatz as19990829\label{fig:as}}
\end{figure}


\begin{figure}
    \centering
    \includestandalone{figures/graphs/data_sets/email}
    \caption{Relative Lösungsqualität für den Datensatz email-Eu-core\label{fig:email}}
\end{figure}

\begin{figure}
    \centering
    \includestandalone{figures/graphs/data_sets/caGrQc}
    \caption{Relative Lösungsqualität für den Datensatz ca-GrQc\label{fig:cagrqc}}
\end{figure}

\begin{figure}
    \centering
    \includestandalone{figures/graphs/data_sets/facebook}
    \caption{Relative Lösungsqualität für den Datensatz ego-Facebook\label{fig:facebook}}
\end{figure}

